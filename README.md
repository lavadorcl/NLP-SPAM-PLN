
# NLP-SPAM-PLN

##  Trabajo Pr谩ctico: Modelado Secuencial y PLN para Problemas del Mundo Real

###  Objetivo General
Aplicar herramientas y modelos de procesamiento del lenguaje natural (PLN), tanto cl谩sicos como basados en aprendizaje profundo, en un contexto real, utilizando PyTorch y TensorFlow.

---

##  Motivaci贸n del Problema
El objetivo fue abordar la clasificaci贸n de mensajes como *spam* o *no spam* mediante modelos de PLN, lo cual es clave en contextos de ciberseguridad, donde se busca prevenir fraudes y comunicaciones maliciosas.

---

##  Descripci贸n del Dataset
Se trabaj贸 con un conjunto de datos etiquetado como `spam_train.csv`, compuesto por 100 frases anotadas manualmente:
- Etiqueta **0**: HAM (mensaje normal)
- Etiqueta **1**: SPAM

Distribuci贸n:
| Clase   | Train | Validation | Train (%) | Validation (%) |
|---------|-------|------------|------------|----------------|
| HAM (0) | 26    | 6          | 32.5%      | 30.0%          |
| SPAM (1)| 54    | 14         | 67.5%      | 70.0%          |

---

##  Parte A: Preprocesamiento y Herramientas de PLN
- Se utiliz贸 **spaCy** para:
  - Tokenizaci贸n
  - Lematizaci贸n
  - Extracci贸n de etiquetas morfosint谩cticas (*POS tags*)
- Se gener贸 una tabla de coincidencia entre las etiquetas obtenidas por spaCy y las extra铆das por un modelo BERT especializado en POS en espa帽ol (`mrm8488/bert-spanish-cased-finetuned-pos`).

---

##  Parte B: Evaluaci贸n con Modelo BERT
- Se utiliz贸 el modelo `mrm8488/bert-spanish-cased-finetuned-pos` de Hugging Face para evaluar el etiquetado POS.
- Se compararon las etiquetas BERT con las de spaCy para medir la coincidencia porcentual.

---

##  Parte C: Modelos Secuenciales con TensorFlow
Se implementaron dos modelos secuenciales:
- **LSTM** (TensorFlow/Keras)
- **GRU** (TensorFlow/Keras)

Resultados:
- Ambos modelos fueron entrenados por 10 茅pocas con *batch size* de 8.
- Se grafic贸 la evoluci贸n de `accuracy` y `loss` para *train* y *validation*.

---

## О Parte D: Comparaci贸n entre Frameworks
- Se reimplementaron los modelos **LSTM** y **GRU** usando **PyTorch**.
- Se replic贸 el entrenamiento con los mismos datos y par谩metros.
- Se graficaron los resultados para comparar rendimiento entre TensorFlow y PyTorch.

---

## М An谩lisis de Resultados
- Los modelos **GRU** y **LSTM** alcanzaron altas precisiones en entrenamiento.
- PyTorch mostr贸 mayor estabilidad en las curvas de *validation loss*.
- El uso de `stratify=y` garantiz贸 una divisi贸n equilibrada entre clases.

---

##  Reflexi贸n Cr铆tica
- El uso combinado de herramientas cl谩sicas (spaCy) y modernas (BERT, LSTM, GRU) permite una evaluaci贸n robusta en tareas de PLN.
- TensorFlow ofrece mayor integraci贸n para usuarios nuevos; PyTorch da mejor control y transparencia.
- Los modelos secuenciales son efectivos incluso con corpus reducidos, si se preprocesan correctamente.

---

##  Archivos Incluidos
- `NLP_spam.ipynb`: Notebook completo con todas las partes.
- `spam_train.csv`: Dataset etiquetado.
- Gr谩ficos generados en matplotlib.

---

##  Autor
Trabajo acad茅mico realizado con fines educativos para la asignatura de PLN y aprendizaje profundo.
